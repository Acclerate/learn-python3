import os
import base64
import fitz  # PyMuPDF
import argparse
import glob
import time
import re
import io
import datetime 
from PIL import Image
from openai import OpenAI
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed
# ================= æ ¸å¿ƒé…ç½®åŒºåŸŸ =================

# 1. [ä¿®æ”¹ç‚¹] ä»ç³»ç»Ÿç¯å¢ƒå˜é‡è·å– API Key
# ä½ çš„ç¯å¢ƒå˜é‡åå¿…é¡»æ˜¯: SiliconFlow_API_KEY
API_KEY = os.getenv("SiliconFlow_API_KEY")

# æ£€æŸ¥ Key æ˜¯å¦å­˜åœ¨
if not API_KEY:
    print("âŒ é”™è¯¯: æœªæ£€æµ‹åˆ°ç¯å¢ƒå˜é‡ 'SiliconFlow_API_KEY'")
    print("ğŸ’¡ æç¤º: å¦‚æœä½ åˆšåˆšæ·»åŠ äº†ç¯å¢ƒå˜é‡ï¼Œè¯·å°è¯•é‡å¯ VS Code æˆ– ç»ˆç«¯çª—å£ã€‚")
    # å¦‚æœä½ ä¸æƒ³ç”¨ç¯å¢ƒå˜é‡ï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡ŒæŠŠä¸Šé¢ä¸¤è¡Œæ³¨é‡Šæ‰ï¼Œç›´æ¥è§£é™¤ä¸‹é¢è¿™è¡Œçš„æ³¨é‡Š:
    # API_KEY = "sk-ä½ çš„å¯†é’¥å†™åœ¨è¿™é‡Œ"
    exit(1)

# 2. æ¨¡å‹é€‰æ‹©
MODEL_NAME = "Qwen/Qwen3-VL-235B-A22B-Thinking" 
BASE_URL = "https://api.siliconflow.cn/v1"

# 3. å¹¶å‘è®¾ç½® (L0ç”¨æˆ·å»ºè®®è®¾ä¸º3-5)
MAX_WORKERS = 5

# 4. åˆ†å—å¤§å° (æ¯ 10 é¡µä¿å­˜ä¸€æ¬¡)
BATCH_SIZE = 10

# 5. åˆå¹¶å¤§å° (æ¯ 60 é¡µåˆå¹¶ä¸ºä¸€ä¸ªå¤§æ–‡ä»¶)
MERGE_CHUNK_SIZE = 60

# 6. åˆ‡å›¾å¾®è°ƒ (å‘å››å‘¨å¤–æ‰©åƒç´ )
PADDING_PIXELS = 3

# ===========================================

# åˆå§‹åŒ–å®¢æˆ·ç«¯
try:
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
except Exception as e:
    print(f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    exit(1)
client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

def clean_ad_content(text):
    """å¼ºåŠ›å»å¹¿å‘Šå‡½æ•°"""
    if not text: return ""
    ad_patterns = [
        r"å…³æ³¨å…¬ä¼—å·\s*ã€\s*è€ƒ\s*ç ”\s*å°\s*èˆŸ\s*ã€‘",
        r"å…è´¹è€ƒç ”èµ„æ–™\s*&\s*æ— æ°´å°\s*PDF",
        r"æ— \s*æ°´\s*å°\s*PDF",
        r"æ‰«\s*æ\s*äºŒ\s*ç»´\s*ç ",
    ]
    cleaned_text = text
    for pattern in ad_patterns:
        cleaned_text = re.sub(pattern, "", cleaned_text, flags=re.IGNORECASE)
    return cleaned_text.strip()

def get_pdf_page_data(doc, page_num, zoom=2.0):
    try:
        page = doc.load_page(page_num)
        pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))
        img_bytes = pix.tobytes("png")
        base64_str = base64.b64encode(img_bytes).decode("utf-8")
        full_b64 = f"data:image/png;base64,{base64_str}"
        pil_img = Image.open(io.BytesIO(img_bytes))
        return pil_img, full_b64
    except Exception as e:
        print(f"âŒ é¡µé¢è¯»å–å¤±è´¥: {e}")
        return None, None

def perform_local_crop(content, pil_img):
    pattern = r'<CUT_IMG>(\d+),(\d+),(\d+),(\d+)</CUT_IMG>'
    
    def replace_with_cropped_image(match):
        try:
            x1_n, y1_n, x2_n, y2_n = map(int, match.groups())
            w, h = pil_img.size
            
            x1 = int(x1_n / 1000 * w)
            y1 = int(y1_n / 1000 * h)
            x2 = int(x2_n / 1000 * w)
            y2 = int(y2_n / 1000 * h)
            
            x1 = max(0, x1 - PADDING_PIXELS)
            y1 = max(0, y1 - PADDING_PIXELS)
            x2 = min(w, x2 + PADDING_PIXELS)
            y2 = min(h, y2 + PADDING_PIXELS)
            
            if x2 <= x1 + 5 or y2 <= y1 + 5: return ""

            crop_img = pil_img.crop((x1, y1, x2, y2))
            buffered = io.BytesIO()
            crop_img.save(buffered, format="PNG")
            img_b64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            return f"\n\n![Figure](data:image/png;base64,{img_b64})\n\n"
        except Exception:
            return ""

    return re.sub(pattern, replace_with_cropped_image, content)

def process_page_workflow(args):
    page_idx, pil_img, b64_img = args
    
    # è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²
    def get_time(): return datetime.datetime.now().strftime("%H:%M:%S")

    # ã€è°ƒè¯•ä¿¡æ¯ã€‘æ‰“å°çº¿ç¨‹å¯åŠ¨æ—¶é—´
    print(f"\n[{get_time()}] ğŸš€ çº¿ç¨‹å¯åŠ¨: ç¬¬ {page_idx+1} é¡µ")

    # ä¼˜åŒ–åçš„ System Promptï¼šç¡®ç«‹ä¸“å®¶äººè®¾ï¼Œå¼ºè°ƒâ€œåˆ¤æ–­â€ä¸â€œæ¸…æ´—â€çš„åŒé‡èŒè´£
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™ææ’ç‰ˆä¸å†…å®¹æ•°å­—åŒ–ä¸“å®¶ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯å®Œç¾è¿˜åŸæ–‡æ¡£å†…å®¹ï¼Œ"
        "æ™ºèƒ½åŒºåˆ†æ–‡æœ¬è½¬æ¢ä¸å›¾åƒä¿ç•™ï¼Œå¹¶ä¸¥æ ¼æ‰§è¡Œå»å¹¿å‘Šæ¸…æ´—ã€‚"
    )
    
    # ä¼˜åŒ–åçš„ User Promptï¼šå…¨ LaTeX å…¬å¼/è¡¨æ ¼ + å¼ºåˆ¶å›¾ç‰‡ç‹¬å è¡Œ
    # ä¼˜åŒ–åçš„ User Promptï¼šé’ˆå¯¹ Obsidian MathJax åšäº†è¯­æ³•åŠ å›º
    user_prompt = (
        "è¯·å¯¹è¿™å¼ æ•™æå›¾ç‰‡è¿›è¡Œå¸ƒå±€åˆ†æä¸å†…å®¹è½¬æ¢ï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¸å¿ƒæŒ‡ä»¤ï¼š\n\n"
        
        "### 1. æ™ºèƒ½åˆ†æµç­–ç•¥\n"
        "- **æ–‡æœ¬å¤„ç†**ï¼šä¸­æ–‡è§£é‡Šæ€§æ–‡å­—ä½¿ç”¨ Markdownã€‚\n"
        "- **æ•°å­¦ä¸è¡¨æ ¼**ï¼š**æ‰€æœ‰**æ•°å­¦å…¬å¼ã€ç¬¦å·ã€æ•°å­—ã€è¡¨æ ¼å¿…é¡»ä½¿ç”¨ LaTeX æ ¼å¼ã€‚\n"
        "- **å¤æ‚å›¾å½¢**ï¼šå‡½æ•°å›¾åƒã€å‡ ä½•å›¾å½¢ã€ç«–å¼è®¡ç®—ç­‰ï¼Œ**ä¸è¦**è½¬æ–‡å­—ï¼Œç›´æ¥è¾“å‡ºåˆ‡å‰²æŒ‡ä»¤ã€‚\n\n"
        
        "### 2. åˆ‡å‰²æŒ‡ä»¤æ ¼å¼\n"
        "- è¾“å‡ºæ ‡ç­¾ï¼š`<CUT_IMG>xmin,ymin,xmax,ymax</CUT_IMG>` ([0,1000] å½’ä¸€åŒ–åæ ‡)ã€‚\n"
        "- **æ’ç‰ˆé“å¾‹**ï¼šå›¾ç‰‡å¿…é¡»**ç‹¬å ä¸€è¡Œ**ï¼Œä½œä¸ºç‹¬ç«‹çš„æ®µè½å­˜åœ¨ã€‚\n"
        "- **ç¦æ­¢äº‹é¡¹**ï¼š**ä¸¥ç¦**å›¾æ–‡æ··æ’ã€‚\n\n"
        
        "### 3. æ’ç‰ˆä¸ LaTeX è§„èŒƒï¼ˆObsidian å…¼å®¹æ€§ä¼˜åŒ–ï¼‰\n"
        "- **å…¬å¼**ï¼šè¡Œå†…å…¬å¼ç”¨ $...$ï¼Œç‹¬å è¡Œå…¬å¼ç”¨ $$...$$ã€‚æ–‡æ®µä¸­çš„å˜é‡ï¼ˆå¦‚ $x$ï¼‰ã€æ•°å­—ï¼ˆå¦‚ $1$ï¼‰ä¹Ÿå¿…é¡»ç”¨ LaTeXã€‚\n"
        "- **è¡¨æ ¼å…³é”®**ï¼š\n"
        "  1. å¿…é¡»ä½¿ç”¨ `\\begin{array}...\\end{array}` ç¯å¢ƒã€‚\n"
        "  2. **æ¢è¡Œå¿…é¡»ä½¿ç”¨åŒåæ–œæ ** `\\\\` (ä¸¥ç¦ä½¿ç”¨å•åæ–œæ )ã€‚\n"
        "  3. **é›†åˆçš„å¤§æ‹¬å·å¿…é¡»è½¬ä¹‰**ï¼Œå†™æˆ `\\{` å’Œ `\\}`ã€‚\n"
        "  4. ä¸¥ç¦ä½¿ç”¨ Markdown è¡¨æ ¼è¯­æ³•ã€‚\n\n"

        "### 4. é€‰æ‹©é¢˜é€‰é¡¹è§„èŒƒ\n"
        "- **æ ¼å¼è¦æ±‚**ï¼šé‡åˆ°é€‰æ‹©é¢˜é€‰é¡¹ï¼ˆA, B, C, Dï¼‰ï¼Œ**å¿…é¡»**è½¬æ¢ä¸º Markdown åˆ—è¡¨æ ¼å¼ï¼Œæ¯ä¸ªé€‰é¡¹ç‹¬å ä¸€è¡Œã€‚\n"
        "- **ç¦æ­¢**ï¼šä¸¥ç¦ä½¿ç”¨ `\\quad`ã€`\\hspace` ç­‰ LaTeX é—´è·å‘½ä»¤æ¥å¼ºè¡Œæ’ç‰ˆä¸€è¡Œã€‚\n"
        "- **èŒƒä¾‹**ï¼š\n"
        "  - (A) $60$\n"
        "  - (B) $63$\n"
        "  - (C) $66$\n"
        "  - (D) $69$\n\n"
        "### 5. å¼ºåŠ›å»å™ª\n"

        "- **å»å¹¿å‘Š**ï¼šç»å¯¹ç¦æ­¢è¾“å‡ºâ€œå…³æ³¨å…¬ä¼—å·ã€è€ƒç ”å°èˆŸã€‘â€ã€â€œå…è´¹è€ƒç ”èµ„æ–™&æ— æ°´å°PDFâ€ç­‰æ°´å°ã€‚\n"
        "- **å»å¹²æ‰°**ï¼šå¿½ç•¥é¡µçœ‰ã€é¡µè„šã€é¡µç ã€äºŒç»´ç ã€‚\n"
        "- **çº¯å‡€è¾“å‡º**ï¼šåªè¾“å‡ºå†…å®¹ï¼Œä¸è¦ä»»ä½•åºŸè¯ã€‚"
        "- **çº¯å‡€è¾“å‡º**ï¼šåªè¾“å‡ºå†…å®¹ï¼Œä¸è¦ä»»ä½•åºŸè¯ã€‚"
    )
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": user_prompt},
                            {"type": "image_url", "image_url": {"url": b64_img}},
                        ],
                    },
                ],
                temperature=0.1, max_tokens=4096
            )
            
            raw_content = response.choices[0].message.content
            final_content = perform_local_crop(raw_content, pil_img)
            final_content = clean_ad_content(final_content)
            
            # ã€è°ƒè¯•ä¿¡æ¯ã€‘æ‰“å°å®Œæˆæ—¶é—´
            print(f"[{get_time()}] âœ… å®Œæˆ: ç¬¬ {page_idx+1} é¡µ")
            return page_idx, final_content

        except Exception as e:
            if "429" in str(e):
                # ã€è°ƒè¯•ä¿¡æ¯ã€‘æ‰“å°è¢«é™æµ
                print(f"[{get_time()}] âš ï¸ é™æµ (ç¬¬ {page_idx+1} é¡µ): ä¼‘çœ 60ç§’é‡è¯•...")
                time.sleep(60)
            else:
                print(f"[{get_time()}] âŒ é”™è¯¯ (ç¬¬ {page_idx+1} é¡µ): {e}")
                return page_idx, f""
    return page_idx, ""

def merge_markdowns_by_chunk(pdf_name, output_dir, final_dir, pages_per_file=60):
    """åˆ†å—åˆå¹¶å‡½æ•°"""
    print(f"ğŸ”„ æ­£åœ¨æŒ‰æ¯ {pages_per_file} é¡µåˆå¹¶æ–‡ä»¶...")
    pattern = os.path.join(output_dir, f"{pdf_name}_part_*.md")
    files = sorted(glob.glob(pattern))
    
    if not files: return

    def get_range(fname):
        match = re.search(r'_part_(\d+)_(\d+)', fname)
        return (int(match.group(1)), int(match.group(2))) if match else (0, 0)

    current_batch_files = []
    current_start_page = -1
    
    for i, fname in enumerate(files):
        s, e = get_range(fname)
        if current_start_page == -1: current_start_page = s
        
        current_batch_files.append(fname)
        
        current_pages = e - current_start_page + 1
        is_last = (i == len(files) - 1)
        
        if current_pages >= pages_per_file or is_last:
            merged_filename = f"{pdf_name}_Merged_{str(current_start_page).zfill(4)}_{str(e).zfill(4)}.md"
            merged_path = os.path.join(final_dir, merged_filename)
            
            with open(merged_path, "w", encoding="utf-8") as outfile:
                outfile.write(f"# {pdf_name} (Pages {current_start_page}-{e})\n\n")
                for batch_f in current_batch_files:
                    with open(batch_f, "r", encoding="utf-8") as infile:
                        outfile.write(infile.read())
                        outfile.write("\n\n---\n\n")
            
            print(f"ğŸ“¦ å·²ç”Ÿæˆåˆå¹¶æ–‡ä»¶: {merged_filename}")
            current_batch_files = []
            current_start_page = -1
    print("ğŸ‰ æ‰€æœ‰åˆ†æ®µåˆå¹¶å®Œæˆï¼")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("pdf_path", help="PDFæ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    if not os.path.exists(args.pdf_path):
        print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
        return

    pdf_name = os.path.splitext(os.path.basename(args.pdf_path))[0]
    work_dir = os.path.join(os.path.dirname(args.pdf_path), f"{pdf_name}_work_dir")
    os.makedirs(work_dir, exist_ok=True)
    
    doc = fitz.open(args.pdf_path)
    total_pages = doc.page_count
    
    print(f"ğŸš€ å¯åŠ¨å…¨è‡ªåŠ¨å¤„ç†: {pdf_name}")
    print(f"ğŸ“„ æ€»é¡µæ•°: {total_pages}")
    print(f"ğŸ“¦ åˆ†å—æ¨¡å¼: æ¯ {BATCH_SIZE} é¡µå­˜æ¡£ä¸€æ¬¡")
    print(f"âš¡ å¹¶å‘çº¿ç¨‹: {MAX_WORKERS}")
    print("-" * 40)

    for batch_start in range(0, total_pages, BATCH_SIZE):
        batch_end = min(batch_start + BATCH_SIZE, total_pages)
        part_filename = f"{pdf_name}_part_{str(batch_start+1).zfill(4)}_{str(batch_end).zfill(4)}.md"
        part_path = os.path.join(work_dir, part_filename)

        if os.path.exists(part_path):
            print(f"âœ… [å·²å®Œæˆ] è·³è¿‡: ç¬¬ {batch_start+1}-{batch_end} é¡µ")
            continue
        
        print(f"âš¡ [å¼€å§‹æ‰¹æ¬¡] ç¬¬ {batch_start+1}-{batch_end} é¡µ ...")
        
        tasks = []
        for i in range(batch_start, batch_end):
            pil_img, b64_img = get_pdf_page_data(doc, i)
            if pil_img:
                tasks.append((i, pil_img, b64_img))

        batch_results = {}
        
        # === [æ ¸å¿ƒä¿®æ”¹] ä¼˜åŒ–çš„å¤šçº¿ç¨‹è¿›åº¦æ˜¾ç¤º ===
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
            future_to_page = {executor.submit(process_page_workflow, task): task[0] for task in tasks}
            
            # ä½¿ç”¨ tqdm.as_completed å®æ—¶æ˜¾ç¤ºå®Œæˆè¿›åº¦
            # desc å‚æ•°ç”¨äºæ˜¾ç¤ºå½“å‰æ‰¹æ¬¡ä¿¡æ¯
            # bar_format ä¼˜åŒ–äº†æ˜¾ç¤ºæ ·å¼
            pbar = tqdm(as_completed(future_to_page), total=len(tasks), 
                       desc=f"Processing {batch_start+1}-{batch_end}", unit="page")
            
            for future in pbar:
                page_idx = future_to_page[future]
                try:
                    p_idx, content = future.result()
                    batch_results[p_idx] = content
                    # æ›´æ–°è¿›åº¦æ¡åçš„æè¿°ï¼Œæ˜¾ç¤ºåˆšå®Œæˆå“ªä¸€é¡µ
                    pbar.set_postfix_str(f"Done: Pg {p_idx+1}")
                except Exception as exc:
                    print(f"\nâŒ Page {page_idx+1} generated an exception: {exc}")
        
        # ä¿å­˜åˆ†å—æ–‡ä»¶
        with open(part_path, "w", encoding="utf-8") as f:
            for i in range(batch_start, batch_end):
                if i in batch_results:
                    f.write(f"\n\n\n\n")
                    f.write(batch_results[i])
                    f.write("\n\n---\n\n")
        
        print(f"ğŸ’¾ å·²å­˜æ¡£: {part_filename}")
        # æ‰¹æ¬¡é—´ç¨å¾®ä¼‘æ¯ï¼Œé˜²æ­¢å¹¶å‘å¤ªçŒ›
        time.sleep(2)

    doc.close()

    final_output_dir = os.path.dirname(args.pdf_path)
    merge_markdowns_by_chunk(pdf_name, work_dir, final_output_dir, pages_per_file=MERGE_CHUNK_SIZE)

if __name__ == "__main__":
    main()