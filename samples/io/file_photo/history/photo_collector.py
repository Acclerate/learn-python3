#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import sys
import tempfile
import zipfile
import shutil
import time
import threading
import queue
import psutil  # ç”¨äºç£ç›˜ç©ºé—´æ£€æŸ¥
from PIL import Image
from concurrent.futures import ThreadPoolExecutor, as_completed

# å°è¯•å¯¼å…¥rarfileï¼Œç”¨äºå¤„ç†RARæ–‡ä»¶
try:
    import rarfile
    RAR_SUPPORT = True
except ImportError:
    RAR_SUPPORT = False
    print("è­¦å‘Š: rarfile æ¨¡å—æœªå®‰è£…ï¼ŒRARæ–‡ä»¶å°†æ— æ³•å¤„ç†ã€‚è¯·è¿è¡Œ: pip install rarfile")

# æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶æ‰©å±•å
IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.heic')
# æ”¯æŒçš„å‹ç¼©æ–‡ä»¶æ‰©å±•å
ARCHIVE_EXTENSIONS = ('.zip', '.rar')

class ParallelPhotoCollector:
    def __init__(self, base_output_dir, max_workers=4, max_depth=10):
        self.base_output_dir = base_output_dir
        self.photo_count = 0
        self.count_lock = threading.Lock()
        self.processed_archives = set()
        self.archive_lock = threading.Lock()
        self.errors = []
        self.error_lock = threading.Lock()
        self.max_depth = max_depth
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.task_queue = queue.Queue()
        self.temp_dirs = []
        self.dir_lock = threading.Lock()
        self.start_time = time.time()
        self.file_counter = 0

    def log_error(self, message):
        with self.error_lock:
            self.errors.append(message)
            print(f"âŒ {message}", file=sys.stderr)

    def increment_count(self):
        with self.count_lock:
            self.photo_count += 1
            self.file_counter += 1
            
            if self.file_counter % 100 == 0:
                elapsed = time.time() - self.start_time
                mins, secs = divmod(int(elapsed), 60)
                hours, mins = divmod(mins, 60)
                print(f"\rğŸ”„ å·²å¤„ç† {self.file_counter} æ–‡ä»¶ | æ‰¾åˆ° {self.photo_count} å¼ å›¾ç‰‡ | "
                      f"è¿è¡Œæ—¶é—´: {hours:02d}:{mins:02d}:{secs:02d} | "
                      f"é˜Ÿåˆ—å¤§å°: {self.task_queue.qsize()}", end="")

    def is_image_file(self, filename):
        return filename.lower().endswith(IMAGE_EXTENSIONS)

    def is_archive_file(self, filename):
        ext = os.path.splitext(filename)[1].lower()
        return ext in ARCHIVE_EXTENSIONS

    def process_image(self, file_path):
        if not file_path.startswith(self.base_output_dir):
            try:
                dest_filename = os.path.basename(file_path)
                dest_path = os.path.join(self.base_output_dir, dest_filename)
                counter = 1
                while os.path.exists(dest_path):
                    name, ext = os.path.splitext(dest_filename)
                    dest_path = os.path.join(self.base_output_dir, f"{name}_{counter}{ext}")
                    counter += 1
                shutil.copy2(file_path, dest_path)
                print(f"ğŸ“· å¤åˆ¶å›¾ç‰‡: {file_path} -> {dest_path}")
            except Exception as e:
                self.log_error(f"å¤åˆ¶å›¾ç‰‡å¤±è´¥ {file_path}: {str(e)}")
        
        try:
            with Image.open(file_path) as img:
                img.verify()
                self.increment_count()
        except (IOError, SyntaxError, Image.DecompressionBombWarning) as e:
            self.log_error(f"æ— æ•ˆå›¾ç‰‡æ–‡ä»¶: {file_path}, é”™è¯¯: {str(e)}")

    def process_entry(self, entry_path, depth=0):
        try:
            if os.path.isdir(entry_path):
                for entry in os.scandir(entry_path):
                    self.task_queue.put((entry.path, depth))
                return

            filename = os.path.basename(entry_path)
            
            if self.is_image_file(filename):
                self.process_image(entry_path)
                return
            
            if self.is_archive_file(filename):
                with self.archive_lock:
                    if entry_path in self.processed_archives:
                        return
                    self.processed_archives.add(entry_path)
                
                if depth >= self.max_depth:
                    self.log_error(f"è¾¾åˆ°æœ€å¤§é€’å½’æ·±åº¦ {self.max_depth}, è·³è¿‡: {entry_path}")
                    return
                
                archive_name = os.path.splitext(os.path.basename(entry_path))[0]
                output_dir = os.path.join(self.base_output_dir, archive_name)
                os.makedirs(output_dir, exist_ok=True)
                
                ext = os.path.splitext(filename)[1].lower()
                if ext == '.zip':
                    self.process_zip(entry_path, output_dir)
                elif ext == '.rar':
                    self.process_rar(entry_path, output_dir)
                
                for root, _, files in os.walk(output_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        self.task_queue.put((file_path, depth + 1))
        except Exception as e:
            self.log_error(f"å¤„ç† {entry_path} æ—¶å‡ºé”™: {str(e)}")

    def process_zip(self, zip_path, output_dir):
        try:
            disk_free = shutil.disk_usage(os.path.dirname(output_dir)).free
            with zipfile.ZipFile(zip_path) as zip_ref:
                # å¤„ç†ä¸­æ–‡æ–‡ä»¶åç¼–ç é—®é¢˜
                for info in zip_ref.infolist():
                    try:
                        # å°è¯•ä½¿ç”¨UTF-8è§£ç 
                        info.filename = info.filename.encode('cp437').decode('utf-8')
                    except UnicodeDecodeError:
                        # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨GBKè§£ç 
                        try:
                            info.filename = info.filename.encode('cp437').decode('gbk')
                        except UnicodeDecodeError:
                            # å¦‚æœéƒ½å¤±è´¥ï¼Œä¿ç•™åŸå§‹æ–‡ä»¶å
                            pass
                total_size = sum(f.file_size for f in zip_ref.infolist())
                if total_size > disk_free * 0.8:
                    raise OSError(f"ç£ç›˜ç©ºé—´ä¸è¶³: éœ€è¦ {total_size} å­—èŠ‚, å¯ç”¨ {disk_free} å­—èŠ‚")
                zip_ref.extractall(output_dir)
                print(f"\nğŸ“¦ è§£å‹ZIP: {zip_path} -> {output_dir}")
        except (zipfile.BadZipFile, OSError) as e:
            self.log_error(f"å¤„ç†ZIPå¤±è´¥ {zip_path}: {str(e)}")

    def process_rar(self, rar_path, output_dir):
        if not RAR_SUPPORT:
            self.log_error(f"æ— æ³•å¤„ç†RARæ–‡ä»¶ {rar_path}: rarfile æ¨¡å—æœªå®‰è£…")
            return
        
        try:
            disk_free = shutil.disk_usage(os.path.dirname(output_dir)).free
            with rarfile.RarFile(rar_path) as rar_ref:
                try:
                    rar_ref.testrar()
                except Exception as e:
                    raise Exception(f"RARæ–‡ä»¶å®Œæ•´æ€§æ ¡éªŒå¤±è´¥: {str(e)}")
                # å¤„ç†ä¸­æ–‡æ–‡ä»¶åç¼–ç é—®é¢˜
                rar_ref.setpassword(None)
                # å°è¯•è®¾ç½®ç¼–ç ä»¥æ­£ç¡®å¤„ç†ä¸­æ–‡æ–‡ä»¶å
                rar_ref.strerror = 'utf-8'
                total_size = sum(f.file_size for f in rar_ref.infolist())
                if total_size > disk_free * 0.8:
                    raise OSError(f"ç£ç›˜ç©ºé—´ä¸è¶³: éœ€è¦ {total_size} å­—èŠ‚, å¯ç”¨ {disk_free} å­—èŠ‚")
                rar_ref.extractall(output_dir)
                print(f"\nğŸ“¦ è§£å‹RAR: {rar_path} -> {output_dir}")
        except (rarfile.RarCannotExec, rarfile.BadRarFile, OSError) as e:
            self.log_error(f"å¤„ç†RARå¤±è´¥ {rar_path}: {str(e)}")

    def worker(self):
        while True:
            try:
                item = self.task_queue.get(timeout=30)
                if item is None:
                    break
                
                path, depth = item
                self.executor.submit(self.process_entry, path, depth)
                self.task_queue.task_done()
            except queue.Empty:
                break

    def cleanup_temp_dirs(self):
        with self.dir_lock:
            for temp_dir in self.temp_dirs:
                if os.path.exists(temp_dir):
                    try:
                        shutil.rmtree(temp_dir)
                        print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
                    except Exception as e:
                        self.log_error(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥ {temp_dir}: {str(e)}")
            self.temp_dirs = []

    def run(self, start_path):
        print(f"â³ å¼€å§‹å¤„ç†: {start_path}")
        self.start_time = time.time()
        
        workers = []
        for _ in range(self.executor._max_workers):
            t = threading.Thread(target=self.worker)
            t.daemon = True
            t.start()
            workers.append(t)
        
        self.task_queue.put((start_path, 0))
        
        try:
            while not self.task_queue.empty() or threading.active_count() > 1:
                time.sleep(1)
                print(f"\rğŸ”„ å¤„ç†ä¸­... å·²æ‰¾åˆ° {self.photo_count} å¼ å›¾ç‰‡ | "
                      f"é˜Ÿåˆ—å¤§å°: {self.task_queue.qsize()} | "
                      f"æ´»åŠ¨çº¿ç¨‹: {threading.active_count()-1}", end="")
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨æ¸…ç†...")
        
        for _ in range(len(workers)):
            self.task_queue.put(None)
        
        for t in workers:
            t.join()
        
        self.cleanup_temp_dirs()
        
        self.executor.shutdown(wait=True)
        
        elapsed = time.time() - self.start_time
        mins, secs = divmod(int(elapsed), 60)
        hours, mins = divmod(mins, 60)
        
        print("\n" + "=" * 60)
        print(f"âœ… å¤„ç†å®Œæˆ! æ€»å…±æ‰¾åˆ° {self.photo_count} å¼ å›¾ç‰‡æ–‡ä»¶")
        print(f"â±ï¸ æ€»è€—æ—¶: {hours:02d}:{mins:02d}:{secs:02d}")
        
        if self.errors:
            print("\nâš ï¸ é‡åˆ°çš„é”™è¯¯ (éƒ¨åˆ†):")
            for error in self.errors[:10]:
                print(f"- {error}")
            if len(self.errors) > 10:
                print(f"- ...å…± {len(self.errors)} ä¸ªé”™è¯¯ï¼Œå®Œæ•´æ—¥å¿—è¯·æŸ¥çœ‹ç¨‹åºè¾“å‡º")
        
        print("=" * 60)

if __name__ == '__main__':
    # For testing with our Chinese filename ZIP
    START_PATH = r"."  # Current directory
    BASE_OUTPUT_DIR = r"./output"
    MAX_WORKERS = 2  # Reduced for testing
    MAX_RECURSION_DEPTH = 5
    
    # Create output directory if it doesn't exist
    os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)
    
    collector = ParallelPhotoCollector(
        base_output_dir=BASE_OUTPUT_DIR,
        max_workers=MAX_WORKERS,
        max_depth=MAX_RECURSION_DEPTH
    )
    collector.run(START_PATH)
    
    result_file = "photo_collection_results.txt"
    with open(result_file, "w", encoding="utf-8") as f:
        f.write(f"å¤„ç†è·¯å¾„: {START_PATH}\n")
        f.write(f"å›¾ç‰‡æ€»æ•°: {collector.photo_count}\n")
        f.write(f"é”™è¯¯æ•°é‡: {len(collector.errors)}\n")
        f.write("\n===== é”™è¯¯æ—¥å¿— =====\n")
        for error in collector.errors:
            f.write(f"{error}\n")
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {result_file}")